---
title: "Mathematical Foundations: Reliability Theory and the Inverse Design Problem"
author: "JoonHo Lee"
date: "`r Sys.Date()`"
description: >
  A rigorous treatment of marginal reliability theory under the 2PL IRT model,
  the global discrimination scaling framework, Jensen's inequality and its
  consequences, monotonicity and existence-uniqueness results, and the
  theoretical foundations of EQC and SAC calibration algorithms.
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Mathematical Foundations: Reliability Theory and the Inverse Design Problem}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE, comment = "#>",
  fig.width = 7, fig.height = 5,
  fig.align = "center", out.width = "85%"
)
```

```{r setup}
library(IRTsimrel)
set.seed(42)
```

## Overview

This vignette provides the mathematical foundations for the reliability-targeted
IRT simulation framework implemented in the IRTsimrel package. It develops the
theory from first principles, connecting classical IRT measurement theory to the
inverse calibration problem solved by the EQC and SAC algorithms.

**Reading time**: approximately 45--60 minutes.

**Prerequisites**: Familiarity with basic probability theory (expectation,
variance, convergence), linear algebra, and the logistic function. Some exposure
to item response theory is helpful but not strictly required.

**Notation conventions**: Random variables are denoted by Greek or capital Roman
letters; vectors are boldfaced; hats denote estimators; bars and tildes denote
specific reliability definitions (defined below).

**Cross-references**: For algorithm-specific details, see
`vignette("algorithm-eqc")` and `vignette("algorithm-sac")`. For applied
examples and workflows, see `vignette("introduction")`.


## The Two-Parameter Logistic IRT Model

We work within the two-parameter logistic (2PL) item response theory model. A
test consists of $I$ items administered to examinees drawn from a latent trait
distribution $G$.

**Definition 1 (2PL Model).** Let $\theta \sim G$ denote a latent ability
parameter and let $(\beta_i, \lambda_i)$ denote the difficulty and
discrimination parameters for item $i$. The probability of a correct response
is given by the item characteristic curve (ICC):

$$
P(X_i = 1 \mid \theta) = \psi\bigl(\lambda_i(\theta - \beta_i)\bigr)
\tag{1}
$$

where $\psi(z) = (1 + e^{-z})^{-1}$ is the standard logistic function.

The Rasch model is the special case where $\lambda_i = 1$ for all items $i$.

### Item and Test Information

The Fisher information provided by item $i$ at ability level $\theta$ is:

**Definition 2 (Item Information).** Under the 2PL model,

$$
\mathcal{J}_i(\theta) = \lambda_i^2\, p_i(\theta)\, \bigl(1 - p_i(\theta)\bigr)
\tag{2}
$$

where $p_i(\theta) = P(X_i = 1 \mid \theta)$ is given by Eq. (1).

Since $p(1-p)$ achieves its maximum of $1/4$ when $p = 1/2$ (i.e., when
$\theta = \beta_i$), the maximum information from item $i$ is
$\lambda_i^2 / 4$.

**Definition 3 (Test Information).** The test information function is the sum of
item information functions:

$$
\mathcal{J}(\theta) = \sum_{i=1}^{I} \mathcal{J}_i(\theta)
  = \sum_{i=1}^{I} \lambda_i^2\, p_i(\theta)\,\bigl(1 - p_i(\theta)\bigr)
\tag{3}
$$

Test information measures the precision of ability estimation at a given
$\theta$. Higher information means smaller standard errors and more precise
measurement.

### The Conditional Standard Error

The asymptotic standard error of the maximum likelihood estimator
$\hat{\theta}$ at $\theta$ is:

$$
\text{SE}(\hat{\theta} \mid \theta) = \frac{1}{\sqrt{\mathcal{J}(\theta)}}
\tag{4}
$$

This conditional error varies across the ability continuum, motivating the need
for _marginal_ (population-averaged) reliability measures.


## Two Definitions of Marginal Reliability

Classical test theory defines reliability as the ratio of true-score variance to
observed-score variance. In IRT, multiple marginalizations are possible,
leading to distinct reliability definitions.

Let $\sigma^2_\theta = \text{Var}_G(\theta)$ denote the latent trait variance
under the population distribution $G$.

### Average-Information Reliability ($\tilde{\rho}$)

**Definition 4 (Average-Information Reliability).** The average-information
marginal reliability is defined as:

$$
\tilde{\rho}(c) = \frac{\sigma^2_\theta\, \bar{\mathcal{J}}(c)}
  {\sigma^2_\theta\, \bar{\mathcal{J}}(c) + 1}
\tag{5}
$$

where $\bar{\mathcal{J}}(c) = \mathbb{E}_G[\mathcal{J}(\theta; c)]$ is the
average test information under $G$.

This definition first averages the test information, then converts to a
reliability-like coefficient. It can be interpreted as the reliability one
would obtain if the _average_ measurement precision applied uniformly across all
examinees.

In the package, this metric is selected with `reliability_metric = "info"` (or
the synonym `"tilde"`).

### MSEM-Based Reliability ($\bar{w}$)

**Definition 5 (MSEM-Based Reliability).** The marginal-standard-error-of-
measurement (MSEM) based reliability is defined as:

$$
\bar{w}(c) = \frac{\sigma^2_\theta}
  {\sigma^2_\theta + \mathbb{E}_G\bigl[1/\mathcal{J}(\theta; c)\bigr]}
\tag{6}
$$

This definition first takes the reciprocal of test information at each
$\theta$ (obtaining the conditional error variance), averages these error
variances, and then forms the reliability ratio. It is the theoretically exact
marginal reliability under the IRT model.

In the package, this metric is selected with `reliability_metric = "msem"` (or
the synonym `"bar"`).

### Jensen's Inequality: $\tilde{\rho} \geq \bar{w}$

The relationship between the two metrics is governed by Jensen's inequality.

**Theorem 1 (Jensen's Inequality for Reliability Metrics).** For any scaling
factor $c > 0$ and any latent distribution $G$ with $\sigma^2_\theta > 0$,

$$
\tilde{\rho}(c) \geq \bar{w}(c)
\tag{7}
$$

with equality if and only if $\mathcal{J}(\theta; c)$ is constant
$G$-almost surely.

**Proof.** The function $f(x) = 1/x$ is strictly convex on $(0, \infty)$. By
Jensen's inequality applied to the random variable
$\mathcal{J}(\theta; c) > 0$:

$$
\mathbb{E}_G\!\left[\frac{1}{\mathcal{J}(\theta; c)}\right]
\geq \frac{1}{\mathbb{E}_G\bigl[\mathcal{J}(\theta; c)\bigr]}
= \frac{1}{\bar{\mathcal{J}}(c)}
\tag{8}
$$

Now compare the denominators of $\tilde{\rho}$ and $\bar{w}$. The denominator
of $\tilde{\rho}$ in Eq. (5) can be rewritten as:

$$
\sigma^2_\theta\, \bar{\mathcal{J}}(c) + 1
= \sigma^2_\theta\, \bar{\mathcal{J}}(c) + 1
$$

while the denominator of $\bar{w}$ in Eq. (6) is:

$$
\sigma^2_\theta + \mathbb{E}_G\!\left[\frac{1}{\mathcal{J}(\theta; c)}\right]
$$

From Eq. (8):

$$
\begin{aligned}
\bar{w}(c)
&= \frac{\sigma^2_\theta}
  {\sigma^2_\theta + \mathbb{E}[1/\mathcal{J}(\theta; c)]}
\leq \frac{\sigma^2_\theta}
  {\sigma^2_\theta + 1/\bar{\mathcal{J}}(c)} \\[6pt]
&= \frac{\sigma^2_\theta\, \bar{\mathcal{J}}(c)}
  {\sigma^2_\theta\, \bar{\mathcal{J}}(c) + 1}
= \tilde{\rho}(c)
\end{aligned}
$$

where the inequality follows from $\mathbb{E}[1/\mathcal{J}] \geq
1/\bar{\mathcal{J}}$ (Jensen) and the monotone decreasing nature of
$x \mapsto \sigma^2_\theta / (\sigma^2_\theta + x)$. Equality holds iff
$\mathcal{J}(\theta; c)$ is a.s. constant, i.e., when information does not
vary across $\theta$. $\square$

### Numerical Verification of Jensen's Inequality

We can verify this inequality computationally using the package's low-level
reliability functions.

```{r jensen-verify}
# Generate a latent trait sample and item parameters
theta <- sim_latentG(5000, shape = "normal")$theta
items <- sim_item_params(25, model = "rasch", source = "parametric")
beta  <- items$data$beta
lambda_base <- rep(1, 25)

# Compute both metrics across a range of c values
c_grid <- seq(0.3, 3.0, by = 0.1)
results <- data.frame(
  c = c_grid,
  rho_tilde = numeric(length(c_grid)),
  rho_bar   = numeric(length(c_grid)),
  gap       = numeric(length(c_grid))
)

for (j in seq_along(c_grid)) {
  both <- compute_rho_both(c_grid[j], theta, beta, lambda_base)
  results$rho_tilde[j] <- both$rho_tilde
  results$rho_bar[j]   <- both$rho_bar
  results$gap[j]       <- both$rho_tilde - both$rho_bar
}

# Verify: gap is always non-negative
cat(sprintf("Jensen's gap range: [%.6f, %.6f]\n",
            min(results$gap), max(results$gap)))
cat(sprintf("All gaps >= 0: %s\n", all(results$gap >= -1e-12)))
```

```{r jensen-plot, fig.cap = "Figure 1: Jensen's gap between the two reliability metrics across scaling factors."}
oldpar <- par(mfrow = c(1, 2), mar = c(4.5, 4.5, 3, 1))
on.exit(par(oldpar))

# Panel 1: Both metrics
plot(results$c, results$rho_tilde, type = "l", col = "steelblue", lwd = 2,
     xlab = "Scaling factor c", ylab = "Reliability",
     main = "Two Reliability Metrics", ylim = c(0, 1))
lines(results$c, results$rho_bar, col = "coral", lwd = 2, lty = 2)
legend("bottomright",
       legend = c(expression(tilde(rho) ~ "(info)"),
                  expression(bar(w) ~ "(msem)")),
       col = c("steelblue", "coral"), lty = c(1, 2), lwd = 2, cex = 0.9)

# Panel 2: The gap
plot(results$c, results$gap, type = "l", col = "darkred", lwd = 2,
     xlab = "Scaling factor c", ylab = expression(tilde(rho) - bar(w)),
     main = "Jensen's Gap")
abline(h = 0, lty = 3, col = "gray50")
```

The gap is largest at intermediate $c$ values where information varies most
across the ability continuum, and shrinks toward zero for very small $c$
(where both metrics approach zero) and very large $c$ (where information
becomes uniformly high).

### Scale Ordering Corollary

**Corollary 1 (Scale Ordering).** Let $c^*_{\tilde{\rho}}$ and
$c^*_{\bar{w}}$ denote the calibrated scaling factors for the same target
$\rho^*$ under the average-information and MSEM metrics, respectively. Then:

$$
c^*_{\bar{w}} \geq c^*_{\tilde{\rho}}
\tag{9}
$$

**Proof sketch.** Since $\tilde{\rho}(c) \geq \bar{w}(c)$ for all $c$, the
MSEM metric reaches any given target level at a larger scaling factor than the
information metric does. Formally, if $\tilde{\rho}(c^*_{\tilde{\rho}}) =
\rho^*$, then
$\bar{w}(c^*_{\tilde{\rho}}) \leq \tilde{\rho}(c^*_{\tilde{\rho}}) = \rho^*$,
so $\bar{w}$ must increase further (requiring larger $c$) to reach $\rho^*$.
$\square$

This ordering is demonstrated numerically below.

```{r scale-ordering}
# Calibrate with both metrics
eqc_info <- eqc_calibrate(
  target_rho = 0.80, n_items = 25, model = "rasch",
  item_source = "parametric", reliability_metric = "info",
  M = 5000L, seed = 42
)

eqc_msem <- eqc_calibrate(
  target_rho = 0.80, n_items = 25, model = "rasch",
  item_source = "parametric", reliability_metric = "msem",
  M = 5000L, seed = 42
)

cat(sprintf("Target rho* = 0.80\n"))
cat(sprintf("  c* (info metric): %.4f\n", eqc_info$c_star))
cat(sprintf("  c* (msem metric): %.4f\n", eqc_msem$c_star))
cat(sprintf("  c*_msem >= c*_info: %s\n",
            eqc_msem$c_star >= eqc_info$c_star - 1e-6))
```


## Global Discrimination Scaling

The central design variable in IRTsimrel is the global discrimination scaling
factor $c > 0$.

### The Scaling Model

**Definition 6 (Global Discrimination Scaling).** Given baseline item
discriminations $\boldsymbol{\lambda}^{(0)} = (\lambda_1^{(0)}, \ldots,
\lambda_I^{(0)})$ generated from an item parameter distribution $H$, the
scaled discriminations are:

$$
\lambda_i(c) = c \cdot \lambda_i^{(0)}, \quad i = 1, \ldots, I
\tag{10}
$$

This scaling has several desirable properties:

1. **Separation of structure and informativeness**: Changing $c$ modifies test
   information without altering the relative difficulty or discrimination
   structure among items.

2. **Dimensionality reduction**: The multi-dimensional item parameter space is
   collapsed to a single scalar control variable $c$.

3. **Smooth dependence**: Both $\tilde{\rho}(c)$ and $\bar{w}(c)$ are smooth
   (infinitely differentiable) functions of $c$ for $c > 0$.

### Monotonicity of $\tilde{\rho}(c)$

**Proposition 1 (Monotonicity; cf. Proposition A.1, Lee 2025).** The
average-information reliability $\tilde{\rho}(c)$ is strictly monotonically
increasing in $c$ for $c > 0$.

**Proof sketch.** We show $\partial \tilde{\rho} / \partial c > 0$. From
Eq. (5), by the chain rule and the fact that $h(x) = x/(x+1)$ is strictly
increasing for $x > 0$, it suffices to show that
$\bar{\mathcal{J}}(c) = \mathbb{E}_G[\mathcal{J}(\theta; c)]$ is strictly
increasing in $c$.

Differentiating the test information:

$$
\frac{\partial \mathcal{J}_i(\theta; c)}{\partial c}
= 2c\, (\lambda_i^{(0)})^2\, p_i(1-p_i)
  + c^2\, (\lambda_i^{(0)})^2\, p_i(1-p_i)(1-2p_i) \cdot \lambda_i^{(0)}(\theta - \beta_i)
$$

After taking the expectation over $G$ and summing over items, the dominant
first-order term $2c\,(\lambda_i^{(0)})^2\,\mathbb{E}[p_i(1-p_i)]$ is
strictly positive for each item $i$ (since $p_i(1-p_i) > 0$ with positive
probability), ensuring $\partial\bar{\mathcal{J}}(c)/\partial c > 0$.

A more rigorous argument uses the representation
$\bar{\mathcal{J}}(c) = c^2 \sum_i (\lambda_i^{(0)})^2
\mathbb{E}[p_i(\theta;c)(1-p_i(\theta;c))]$
and the fact that $\mathbb{E}[p_i(1-p_i)]$ is bounded away from zero under
regularity conditions. $\square$

### Existence and Uniqueness

**Corollary 2 (Existence and Uniqueness; cf. Corollary 2.1, Lee 2025).**
Under mild regularity conditions, for any target $\rho^* \in (\rho_{\min},
\rho_{\max})$ where

$$
\rho_{\min} = \lim_{c \to 0^+} \tilde{\rho}(c) = 0
\quad\text{and}\quad
\rho_{\max} = \lim_{c \to \infty} \tilde{\rho}(c) = 1,
$$

there exists a unique $c^* > 0$ satisfying $\tilde{\rho}(c^*) = \rho^*$.

**Proof.** Since $\tilde{\rho}$ is continuous (composition of continuous
functions), strictly increasing (Proposition 1), and maps $(0,\infty)$ onto
$(0,1)$, existence and uniqueness follow from the intermediate value theorem
and strict monotonicity. $\square$

### Non-Monotonicity of $\bar{w}(c)$

**Proposition 2 (Non-Monotonicity of MSEM; cf. Proposition A.5, Lee 2025).**
The MSEM-based reliability $\bar{w}(c)$ is *not* necessarily monotone in $c$
over the entire positive real line. In particular, for sufficiently large $c$,
$\bar{w}(c)$ can decrease.

**Intuition.** As $c \to \infty$, for most $\theta$ values far from any
$\beta_i$, the item response probabilities $p_i(\theta)$ approach 0 or 1,
causing item information $\mathcal{J}_i(\theta) = \lambda_i^2 p_i(1-p_i) \to 0$.
Only $\theta$ values very close to some $\beta_i$ retain high information. The
harmonic mean (used in $\bar{w}$) is dominated by the low-information regions,
causing $\mathbb{E}[1/\mathcal{J}]$ to grow and $\bar{w}$ to decrease.

The arithmetic mean (used in $\tilde{\rho}$) is not as sensitive to these low-
information tails, which is why $\tilde{\rho}$ remains monotone.

This is why the `c_bounds` parameter matters in practice, especially when using
the `"msem"` metric.

```{r non-monotone-msem, fig.cap = "Figure 2: Non-monotonicity of the MSEM metric at extreme scaling factors (heavy-tailed latent distribution, df = 3)."}
# Demonstrate non-monotonicity with a heavy-tailed distribution.
# Non-monotonicity is most prominent with heavy tails because extreme
# theta values far from any beta_i have near-zero information, and
# the harmonic mean (used in rho_bar) is dominated by these regions.
theta_nm <- sim_latentG(5000, shape = "heavy_tail", shape_params = list(df = 3))$theta

# Use 10 items with concentrated difficulties for a more visible effect
items_nm <- sim_item_params(10, model = "rasch", source = "parametric")
beta_nm  <- items_nm$data$beta
lambda_nm <- rep(1, 10)

c_wide <- seq(0.1, 15, length.out = 100)
rho_t <- rho_b <- numeric(length(c_wide))

for (j in seq_along(c_wide)) {
  both <- compute_rho_both(c_wide[j], theta_nm, beta_nm, lambda_nm)
  rho_t[j] <- both$rho_tilde
  rho_b[j] <- both$rho_bar
}

oldpar <- par(mar = c(4.5, 4.5, 3, 1))
on.exit(par(oldpar))

plot(c_wide, rho_t, type = "l", col = "steelblue", lwd = 2,
     xlab = "Scaling factor c", ylab = "Reliability",
     main = "Monotonicity Comparison (Heavy-Tailed Latent, df = 3)",
     ylim = c(0, 1))
lines(c_wide, rho_b, col = "coral", lwd = 2, lty = 2)

# Mark the maximum of rho_bar
idx_max <- which.max(rho_b)
points(c_wide[idx_max], rho_b[idx_max], pch = 19, col = "coral", cex = 1.5)

legend("right",
       legend = c(expression(tilde(rho) ~ "(always monotone)"),
                  expression(bar(w) ~ "(non-monotone at extreme c)")),
       col = c("steelblue", "coral"), lty = c(1, 2), lwd = 2, cex = 0.85)

cat(sprintf("rho_bar maximum at c = %.2f with value %.4f\n",
            c_wide[idx_max], rho_b[idx_max]))
cat(sprintf("rho_bar at c = %.1f: %.4f (decreasing)\n",
            max(c_wide), rho_b[length(c_wide)]))
```


## Achievable Reliability Bounds

Not every target reliability is achievable for a given test configuration.
The feasible range depends on the number of items, the item parameter
distribution, and the latent trait distribution.

### Upper Bound from the Logistic Kernel

**Proposition 3 (Information Upper Bound).** Under the 2PL model, the maximum
item information is:

$$
\sup_{\theta}\, \mathcal{J}_i(\theta) = \frac{\lambda_i^2}{4}
\tag{11}
$$

achieved when $\theta = \beta_i$ (i.e., $p_i = 1/2$). Therefore, the maximum
test information is:

$$
\sup_{\theta}\, \mathcal{J}(\theta; c) = \frac{c^2}{4} \sum_{i=1}^{I} (\lambda_i^{(0)})^2
\tag{12}
$$

For the Rasch model with $\lambda_i^{(0)} = 1$, this simplifies to
$c^2 I / 4$.

**Proof.** The function $p(1-p)$ on $[0,1]$ has a unique maximum of $1/4$ at
$p = 1/2$. Under the 2PL model, $p_i(\theta) = 1/2$ when
$\theta = \beta_i$. $\square$

### Feasibility Conditions

The average test information is bounded above by the maximum:

$$
\bar{\mathcal{J}}(c) = \mathbb{E}_G\!\left[\sum_{i=1}^{I} \lambda_i(c)^2\, p_i(1-p_i)\right]
\leq \frac{c^2}{4} \sum_{i=1}^{I} (\lambda_i^{(0)})^2
$$

Therefore the maximum achievable average-information reliability for a given $c$
is:

$$
\tilde{\rho}_{\max}(c) = \frac{\sigma^2_\theta \cdot (c^2/4) \sum_i (\lambda_i^{(0)})^2}
  {\sigma^2_\theta \cdot (c^2/4) \sum_i (\lambda_i^{(0)})^2 + 1}
$$

As $c \to \infty$, this approaches 1, but in practice we work within
$c \in [c_{\min}, c_{\max}]$ and the achievable range is finite.

### Connection to `check_feasibility()`

The `check_feasibility()` function computes the achievable reliability range
via Monte Carlo evaluation at the boundary scaling factors.

```{r feasibility}
# Check feasibility for a 25-item Rasch test
feas <- check_feasibility(
  n_items = 25, model = "rasch",
  latent_shape = "normal",
  item_source = "parametric",
  c_bounds = c(0.1, 10),
  M = 5000L, seed = 42
)
```

```{r feasibility-targets}
# Test which targets are feasible
targets <- c(0.50, 0.70, 0.80, 0.90, 0.95)
for (rho in targets) {
  feasible_info <- rho >= feas$rho_range_info[1] & rho <= feas$rho_range_info[2]
  feasible_msem <- rho >= feas$rho_range_msem[1] & rho <= feas$rho_range_msem[2]
  cat(sprintf("  rho* = %.2f: info %s, msem %s\n",
              rho,
              ifelse(feasible_info, "YES", "NO "),
              ifelse(feasible_msem, "YES", "NO ")))
}
```

### Reliability Curves

The `rho_curve()` function visualizes how reliability changes with the
scaling factor.

```{r rho-curve, fig.cap = "Figure 3: Reliability curve for a 25-item Rasch test under a normal latent distribution."}
curve_data <- rho_curve(
  c_values = seq(0.1, 5, length.out = 60),
  n_items = 25, model = "rasch",
  latent_shape = "normal",
  item_source = "parametric",
  metric = "both",
  M = 5000L, seed = 42,
  plot = TRUE
)
```


## EQC Theory: Deterministic Root-Finding

The Empirical Quadrature Calibration (EQC) algorithm solves the inverse
reliability problem using deterministic root-finding on an empirical
reliability function. Full algorithmic details are in
`vignette("algorithm-eqc")`; here we state the main theoretical results.

### Algorithm Sketch

EQC proceeds in three steps:

1. **Quadrature sampling**: Draw $\{\theta_m\}_{m=1}^M \sim G$ and item
   parameters $\{(\beta_i, \lambda_i^{(0)})\}_{i=1}^I \sim H$ once.

2. **Empirical reliability function**: For any $c > 0$, define:
   $$
   \hat{\rho}_M(c) = \rho\bigl(c;\, \{\theta_m\},\, \boldsymbol{\beta},\,
   \boldsymbol{\lambda}(c)\bigr)
   \tag{13}
   $$

3. **Root-finding**: Solve $g_M(c) = \hat{\rho}_M(c) - \rho^* = 0$ using
   Brent's method on $[c_{\min}, c_{\max}]$.

### Consistency

**Theorem 2 (Consistency of EQC; cf. Theorem A.1, Lee 2025).** Let $c^*$ be
the true population solution and $\hat{c}^*_M$ be the EQC solution with
quadrature size $M$. Then:

$$
\hat{c}^*_M \xrightarrow{\text{a.s.}} c^* \quad \text{as } M \to \infty
\tag{14}
$$

**Proof sketch.** The empirical reliability $\hat{\rho}_M(c)$ converges
uniformly to $\rho(c)$ over the compact interval $[c_{\min}, c_{\max}]$ by
the Uniform Law of Large Numbers (ULLN). Since $\rho(c)$ is continuous and
strictly monotone, and the root of the limit function is unique (Corollary 2),
uniform convergence of the objective implies convergence of the root (by the
continuous mapping theorem for M-estimators). $\square$

### Asymptotic Normality

**Theorem 3 (Asymptotic Normality of EQC; cf. Theorem A.2, Lee 2025).** Under
regularity conditions, the EQC estimator satisfies:

$$
\sqrt{M}\,\bigl(\hat{c}^*_M - c^*\bigr) \xrightarrow{d}
N\!\left(0,\, \frac{\sigma^2_g}{g'(c^*)^2}\right)
\tag{15}
$$

where $g(c) = \rho(c) - \rho^*$, $g'(c^*)$ is the derivative of the
reliability function at the solution, and $\sigma^2_g$ is the asymptotic
variance of the empirical gradient.

**Proof sketch.** Apply the delta method to the implicit function
$\hat{c}^*_M = g^{-1}_M(\rho^*)$. The Central Limit Theorem gives
$\sqrt{M}(\hat{\rho}_M(c) - \rho(c)) \to_d N(0, \sigma^2_g)$, and the
implicit function theorem (applicable since $g'(c^*) \neq 0$ by strict
monotonicity) yields the result. $\square$

### Monte Carlo Error Bounds

The practical implication of Theorem 3 is:

$$
|\hat{c}^*_M - c^*| = O_p\!\left(\frac{1}{\sqrt{M}}\right)
\tag{16}
$$

The reliability estimate itself has error:

$$
|\hat{\rho}_M(c) - \rho(c)| = O_p\!\left(\frac{1}{\sqrt{M}}\right)
$$

| Quadrature size $M$ | Approx. MC std. error |
|---------------------:|:---------------------:|
| 1,000               | ~0.03                 |
| 5,000               | ~0.014                |
| 10,000              | ~0.01                 |
| 50,000              | ~0.004                |
| 100,000             | ~0.003                |


## SAC Theory: Stochastic Approximation

The Stochastic Approximation Calibration (SAC) algorithm provides an
independent solution path using the Robbins-Monro framework. Full algorithmic
details are in `vignette("algorithm-sac")`.

### The Stochastic Root-Finding Problem

SAC targets the equation:

$$
g(c) = \mathbb{E}\!\left[\hat{\rho}(c)\right] - \rho^* = 0
\tag{17}
$$

At each iteration $n$, only a noisy observation
$\hat{\rho}_n(c_n) = \rho^* + g(c_n) + \varepsilon_n$ is available, where
$\varepsilon_n$ is zero-mean Monte Carlo noise.

### Robbins-Monro Update

The iterative update rule is:

$$
c_{n+1} = \Pi_{[c_L, c_U]}\!\left[c_n - a_n\,\bigl(\hat{\rho}_n(c_n) - \rho^*\bigr)\right]
\tag{18}
$$

where $\Pi_{[c_L, c_U]}$ denotes projection onto the constraint set and the
step size sequence satisfies the Robbins-Monro conditions:

$$
a_n = \frac{a}{(n + A)^\gamma}, \quad
\sum_{n=1}^{\infty} a_n = \infty, \quad
\sum_{n=1}^{\infty} a_n^2 < \infty
\tag{19}
$$

These conditions are satisfied when $\gamma \in (1/2, 1]$.

### Polyak-Ruppert Averaging

Rather than using the final iterate $c_N$, SAC computes the Polyak-Ruppert
average over post-burn-in iterates:

$$
\bar{c}_N = \frac{1}{N - B} \sum_{n=B+1}^{N} c_n
\tag{20}
$$

where $B$ is the burn-in period. This averaging achieves the optimal
convergence rate.

### Convergence

**Theorem 4 (SAC Convergence; cf. Theorem A.3, Lee 2025).** Under the
Robbins-Monro conditions (Eq. 19) and standard regularity assumptions
(boundedness of $g$, Lipschitz continuity, noise variance bounded), the SAC
iterates converge almost surely:

$$
c_n \xrightarrow{\text{a.s.}} c^* \quad \text{as } n \to \infty
\tag{21}
$$

Furthermore, the Polyak-Ruppert average satisfies:

$$
\sqrt{N - B}\,(\bar{c}_N - c^*) \xrightarrow{d}
N\!\left(0,\, \frac{\sigma^2_\varepsilon}{g'(c^*)^2}\right)
\tag{22}
$$

achieving the optimal $O(n^{-1/2})$ rate, compared to $O(n^{-\gamma})$ for
the final iterate.

**Proof sketch.** Almost sure convergence follows from the classical
Robbins-Monro theorem (Robbins and Monro, 1951), extended to the projected
case by Kushner and Yin (2003). The key conditions are: (i) $g(c^*) = 0$,
(ii) $g'(c^*) > 0$ (strict monotonicity from Proposition 1), (iii) the step
size conditions in Eq. (19), and (iv) bounded conditional variance
$\text{Var}(\varepsilon_n \mid c_n) \leq \sigma^2_\varepsilon$. Asymptotic
normality of the Polyak-Ruppert average follows from Polyak and Juditsky
(1992). $\square$


## Numerical Demonstrations

### Verifying Theoretical Predictions

We use the low-level reliability functions to verify key theoretical
properties.

```{r demo-setup}
# Common setup for demonstrations
M_demo <- 5000L
theta_demo <- sim_latentG(M_demo, shape = "normal")$theta
items_demo <- sim_item_params(30, model = "rasch", source = "parametric")
beta_demo  <- items_demo$data$beta
lambda_demo <- rep(1, 30)
theta_var_demo <- var(theta_demo)
```

#### Verification 1: Reliability increases with c (info metric)

```{r verify-monotone}
c_test <- c(0.5, 1.0, 1.5, 2.0, 2.5, 3.0)
rho_info <- sapply(c_test, function(cc) {
  compute_rho_tilde(cc, theta_demo, beta_demo, lambda_demo,
                    theta_var = theta_var_demo)
})

cat("Monotonicity check (info metric):\n")
for (j in seq_along(c_test)) {
  cat(sprintf("  c = %.1f: rho_tilde = %.4f", c_test[j], rho_info[j]))
  if (j > 1) {
    cat(sprintf("  (diff = %+.4f)", rho_info[j] - rho_info[j-1]))
  }
  cat("\n")
}
cat(sprintf("All differences positive: %s\n", all(diff(rho_info) > 0)))
```

#### Verification 2: Jensen's gap depends on information heterogeneity

Non-standard latent distributions produce larger Jensen's gaps because
information varies more across the ability continuum.

```{r verify-gap-shapes}
shapes <- c("normal", "bimodal", "heavy_tail", "skew_pos")
shape_pars <- list(
  normal     = list(),
  bimodal    = list(delta = 0.9),
  heavy_tail = list(df = 5),
  skew_pos   = list(k = 4)
)

c_val <- 1.5
cat(sprintf("Jensen's gap at c = %.1f for different latent shapes:\n", c_val))

for (sh in shapes) {
  theta_sh <- sim_latentG(M_demo, shape = sh, shape_params = shape_pars[[sh]])$theta
  both_sh <- compute_rho_both(c_val, theta_sh, beta_demo, lambda_demo)
  gap <- both_sh$rho_tilde - both_sh$rho_bar
  cat(sprintf("  %-12s: rho_tilde = %.4f, rho_bar = %.4f, gap = %.4f\n",
              sh, both_sh$rho_tilde, both_sh$rho_bar, gap))
}
```

#### Verification 3: APC initialization quality

The Analytic Pre-Calibration (APC) formula provides a closed-form starting
point. We compare it against the EQC solution.

```{r verify-apc}
targets <- c(0.60, 0.70, 0.80, 0.85, 0.90)
cat("APC initialization vs EQC solution (Rasch, 25 items, normal):\n")
cat(sprintf("  %-10s %-10s %-10s %-10s\n", "Target", "c_APC", "c_EQC", "Ratio"))

for (rho_t in targets) {
  c_apc <- compute_apc_init(target_rho = rho_t, n_items = 25)
  eqc_t <- eqc_calibrate(
    target_rho = rho_t, n_items = 25, model = "rasch",
    item_source = "parametric", M = 5000L, seed = 42, verbose = FALSE
  )
  cat(sprintf("  %-10.2f %-10.4f %-10.4f %-10.2f\n",
              rho_t, c_apc, eqc_t$c_star, c_apc / eqc_t$c_star))
}
```

#### Verification 4: Effect of test length on achievable reliability

```{r verify-test-length}
n_items_grid <- c(10, 15, 20, 25, 30, 40, 50)
c_fixed <- 1.0

cat(sprintf("Reliability at c = %.1f for different test lengths:\n", c_fixed))
for (ni in n_items_grid) {
  items_ni <- sim_item_params(ni, model = "rasch", source = "parametric")
  beta_ni  <- items_ni$data$beta
  lambda_ni <- rep(1, ni)

  both_ni <- compute_rho_both(c_fixed, theta_demo, beta_ni, lambda_ni,
                               theta_var = theta_var_demo)
  cat(sprintf("  I = %2d: rho_tilde = %.4f, rho_bar = %.4f\n",
              ni, both_ni$rho_tilde, both_ni$rho_bar))
}
```

### EQC vs SAC Agreement

```{r eqc-sac-agree}
eqc_demo <- eqc_calibrate(
  target_rho = 0.80, n_items = 25, model = "rasch",
  item_source = "parametric", reliability_metric = "info",
  M = 5000L, seed = 42, verbose = FALSE
)

sac_demo <- sac_calibrate(
  target_rho = 0.80, n_items = 25, model = "rasch",
  item_source = "parametric", reliability_metric = "info",
  c_init = eqc_demo, n_iter = 300L, M_per_iter = 1000L,
  seed = 42, verbose = FALSE
)

cat("EQC vs SAC comparison (target = 0.80, info metric):\n")
cat(sprintf("  EQC c*:        %.4f\n", eqc_demo$c_star))
cat(sprintf("  SAC c*:        %.4f\n", sac_demo$c_star))
cat(sprintf("  Abs diff:      %.4f\n", abs(eqc_demo$c_star - sac_demo$c_star)))
cat(sprintf("  Pct diff:      %.2f%%\n",
            100 * abs(eqc_demo$c_star - sac_demo$c_star) / eqc_demo$c_star))
```

### Verification 5: Reliability function under the 2PL model

The 2PL model introduces additional variability through heterogeneous
baseline discriminations.

```{r verify-2pl}
items_2pl <- sim_item_params(25, model = "2pl", source = "parametric")
beta_2pl  <- items_2pl$data$beta
lambda_2pl <- if ("lambda_unscaled" %in% names(items_2pl$data)) {
  items_2pl$data$lambda_unscaled
} else {
  items_2pl$data$lambda
}

cat("2PL baseline discriminations:\n")
cat(sprintf("  Range: [%.3f, %.3f]\n", min(lambda_2pl), max(lambda_2pl)))
cat(sprintf("  Mean:  %.3f\n", mean(lambda_2pl)))
cat(sprintf("  SD:    %.3f\n", sd(lambda_2pl)))

# Compare Rasch and 2PL reliability at same c
c_compare <- 1.0
both_rasch <- compute_rho_both(c_compare, theta_demo,
                                beta_demo[1:25], rep(1, 25),
                                theta_var = theta_var_demo)
both_2pl <- compute_rho_both(c_compare, theta_demo,
                              beta_2pl, lambda_2pl,
                              theta_var = theta_var_demo)

cat(sprintf("\nReliability comparison at c = %.1f:\n", c_compare))
cat(sprintf("  Rasch: rho_tilde = %.4f, rho_bar = %.4f, gap = %.4f\n",
            both_rasch$rho_tilde, both_rasch$rho_bar,
            both_rasch$rho_tilde - both_rasch$rho_bar))
cat(sprintf("  2PL:   rho_tilde = %.4f, rho_bar = %.4f, gap = %.4f\n",
            both_2pl$rho_tilde, both_2pl$rho_bar,
            both_2pl$rho_tilde - both_2pl$rho_bar))
```

Heterogeneous discriminations typically produce a larger Jensen's gap because
the test information varies more across the ability continuum.


## The Inverse Design Problem

The theoretical framework above describes the _forward_ problem: given a
scaling factor $c$, compute the reliability $\rho(c)$. The central
contribution of the IRTsimrel package is solving the _inverse_ problem.

### Problem Statement

**Definition 7 (Inverse Reliability Problem).** Given a target marginal
reliability $\rho^* \in (0, 1)$, find a global discrimination scaling factor
$c^* > 0$ such that:

$$
\rho(c^*) = \rho^*
\tag{23}
$$

where $\rho$ denotes either $\tilde{\rho}$ (average-information) or $\bar{w}$
(MSEM-based), depending on the chosen metric.

### Why the Inverse Problem is Difficult

Several factors make this inverse problem non-trivial:

1. **No closed-form solution**: The reliability function involves a logistic
   nonlinearity inside an expectation over $G$. Even in the simplest Rasch
   case with normal $G$, no analytic inversion is possible.

2. **Distribution dependence**: The mapping $c \mapsto \rho(c)$ depends on
   the full distributions $G$ (latent traits) and $H$ (item parameters), not
   just their moments.

3. **Metric ambiguity**: The two reliability definitions yield different $c^*$
   values for the same target (Corollary 1).

4. **Practical constraints**: The scaling factor must lie within bounds that
   produce realistic item parameters.

### The APC Approximation

The Analytic Pre-Calibration (APC) formula provides a rough initial estimate
under Gaussian Rasch assumptions. With $\theta \sim N(0,1)$ and
$\beta \sim N(0, \sigma^2_\beta)$, the expected item information involves
the logistic-normal convolution constant:

$$
\kappa(\sigma^2) = \int_{-\infty}^{\infty}
\frac{e^z}{(1+e^z)^2}\, \phi(z; 0, \sigma^2)\, dz
\approx \frac{0.25}{\sqrt{1 + \sigma^2 \pi^2 / 3}}
\tag{24}
$$

where $\sigma^2 = 1 + \sigma^2_\beta$. The APC initial value is:

$$
c_{\text{APC}} = \sqrt{\frac{\rho^*}{I \cdot \kappa \cdot (1 - \rho^*)}}
\tag{25}
$$

This approximation is typically within a factor of 2 of the true $c^*$ and
serves as a starting point for the stochastic approximation algorithm (SAC).


## Complete Notation Table

The following table summarizes all mathematical notation used in the package
and its documentation.

| Symbol | Description | Domain |
|:------:|:-----------|:------:|
| $\theta$ | Latent ability parameter | $\mathbb{R}$ |
| $G$ | Latent trait distribution | -- |
| $\sigma^2_\theta$ | Variance of $\theta$ under $G$ | $(0, \infty)$ |
| $\beta_i$ | Difficulty parameter for item $i$ | $\mathbb{R}$ |
| $\lambda_i$ | Discrimination parameter for item $i$ | $(0, \infty)$ |
| $\lambda_i^{(0)}$ | Baseline (unscaled) discrimination | $(0, \infty)$ |
| $c$ | Global discrimination scaling factor | $(0, \infty)$ |
| $c^*$ | Calibrated scaling factor | $(0, \infty)$ |
| $I$ | Number of items | $\mathbb{N}$ |
| $M$ | Quadrature (Monte Carlo) sample size | $\mathbb{N}$ |
| $\psi(z)$ | Logistic function $1/(1+e^{-z})$ | $(0, 1)$ |
| $p_i(\theta)$ | $P(X_i = 1 \mid \theta)$; ICC | $(0, 1)$ |
| $\mathcal{J}_i(\theta)$ | Item information function | $(0, \infty)$ |
| $\mathcal{J}(\theta)$ | Test information function | $(0, \infty)$ |
| $\bar{\mathcal{J}}(c)$ | Average test information $\mathbb{E}_G[\mathcal{J}(\theta;c)]$ | $(0, \infty)$ |
| $\tilde{\rho}(c)$ | Average-information reliability | $(0, 1)$ |
| $\bar{w}(c)$ | MSEM-based reliability | $(0, 1)$ |
| $\rho^*$ | Target reliability | $(0, 1)$ |
| $\hat{\rho}_M(c)$ | Empirical reliability (EQC) | $(0, 1)$ |
| $\hat{\rho}_n(c)$ | Noisy reliability estimate (SAC) | $(0, 1)$ |
| $a_n$ | Step size at iteration $n$ | $(0, \infty)$ |
| $a$ | Step size constant (SAC) | $(0, \infty)$ |
| $A$ | Stabilization constant (SAC) | $[0, \infty)$ |
| $\gamma$ | Step decay exponent (SAC) | $(1/2, 1]$ |
| $B$ | Burn-in period (SAC) | $\mathbb{N}_0$ |
| $N$ | Total number of SAC iterations | $\mathbb{N}$ |
| $\bar{c}_N$ | Polyak-Ruppert average | $(0, \infty)$ |
| $\kappa$ | Logistic-normal convolution constant (APC) | $(0, 1/4)$ |
| $H$ | Item parameter distribution | -- |
| $\text{MSEM}$ | $\mathbb{E}[1/\mathcal{J}(\theta;c)]$ | $(0, \infty)$ |


## Summary of Theoretical Results

| Result | Statement | Implication |
|:-------|:----------|:------------|
| **Theorem 1** | $\tilde{\rho}(c) \geq \bar{w}(c)$ (Jensen) | Info metric always yields higher reliability values |
| **Corollary 1** | $c^*_{\bar{w}} \geq c^*_{\tilde{\rho}}$ | MSEM metric requires larger scaling factor |
| **Proposition 1** | $\tilde{\rho}(c)$ is strictly increasing | Existence and uniqueness for info metric |
| **Corollary 2** | Unique $c^*$ exists for $\rho^* \in (0,1)$ | EQC root-finding is well-defined |
| **Proposition 2** | $\bar{w}(c)$ is not always monotone | `c_bounds` critical for MSEM metric |
| **Proposition 3** | $\max \mathcal{J}_i = \lambda_i^2/4$ | Upper bound on achievable reliability |
| **Theorem 2** | EQC consistent ($\hat{c}^*_M \to c^*$ a.s.) | Arbitrarily precise via larger $M$ |
| **Theorem 3** | EQC asymptotically normal ($\sqrt{M}$ rate) | Quantifiable uncertainty |
| **Theorem 4** | SAC converges a.s., optimal rate with PR avg | Independent validation pathway |


## References

Lee, J. (2025). Reliability-targeted simulation of item response data: Solving
the inverse design problem. *arXiv preprint arXiv:2512.16012*.

Robbins, H., & Monro, S. (1951). A stochastic approximation method. *The Annals
of Mathematical Statistics, 22*(3), 400--407.

Polyak, B. T., & Juditsky, A. B. (1992). Acceleration of stochastic
approximation by averaging. *SIAM Journal on Control and Optimization, 30*(4),
838--855.

Kushner, H. J., & Yin, G. G. (2003). *Stochastic Approximation and Recursive
Algorithms and Applications* (2nd ed.). Springer.

Brent, R. P. (1973). *Algorithms for Minimization Without Derivatives*.
Prentice-Hall.

Lord, F. M. (1980). *Applications of Item Response Theory to Practical Testing
Problems*. Erlbaum.

van der Linden, W. J. (Ed.). (2016). *Handbook of Item Response Theory* (Vols.
1--3). CRC Press.

Birnbaum, A. (1968). Some latent trait models and their use in inferring an
examinee's ability. In F. M. Lord & M. R. Novick (Eds.), *Statistical Theories
of Mental Test Scores* (pp. 395--479). Addison-Wesley.
